# Examples

`alma` will have to be installed for these examples to work.
[See installation steps](../README.md#installation)

## Overview
The examples on how to use `alma` are located here in the `examples` directory. The examples are:

- [`mnist`](./mnist/README.md#mnist-example): A simple example of training a model on the MNIST dataset and benchmarking the model
    speed for different conversion options. There are also many details on how to quantize the model,
    for both Eager mode and FX Graph mode, using PTQ and QAT.
- [`linear`](./linear/README.md#simple-linear-example): A barebones example of a linear layer and ReLU activation, where we demonstrate
    just the benchmarking without any training. 


